{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# States.h5\n",
    "这个文件中需要包含各个state的状态，不同的state放入不同的HDF5 dataset中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'output1', <HDF5 dataset \"output1\": shape (1271900, 200), type \"<f4\">)\n",
      "(u'states1', <HDF5 dataset \"states1\": shape (1271900, 200), type \"<f4\">)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('E:\\\\AprilPaper\\\\LSTMVis\\\\05childbook\\\\states.h5','r') as f:\n",
    "    for i in f.iteritems():\n",
    "        print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每一个dataset中都是一个np.array\n",
    "结构应该为```[[state_time1_vector],[state_time2_vector],...,[state_timen_vector]]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.dataset.Dataset'>\n",
      "(1271900, 200)\n",
      "<type 'numpy.ndarray'>\n",
      "(1L, 200L)\n",
      "[[  5.81289887e-01   3.39919410e-04  -2.76827607e-02  -4.30688828e-01\n",
      "    3.30461264e-02  -4.38991897e-02  -1.12472847e-01  -6.80815399e-01\n",
      "    5.39585173e-01   6.20811991e-03   6.89229727e-01   3.75992805e-01\n",
      "    3.08797985e-01   1.30948901e-01   7.05615282e-01  -1.57362506e-01\n",
      "    6.77180350e-01  -6.32081270e-01   7.37105072e-01   1.07607767e-01\n",
      "   -2.69082487e-01  -1.31932404e-02  -8.24198052e-02  -2.63573974e-01\n",
      "    5.90528309e-01  -1.19118668e-01  -7.01427281e-01  -3.48605454e-01\n",
      "    1.02392947e-02  -1.01775741e-02   6.81875944e-01  -9.75633413e-02\n",
      "   -7.72304367e-04  -6.23239815e-01  -1.89329442e-02   6.61468148e-01\n",
      "    2.89940774e-01  -1.64694339e-01  -6.54118657e-01  -5.92946827e-01\n",
      "    3.88067186e-01   1.72183588e-02   6.20050065e-04  -1.70851145e-02\n",
      "    1.04368560e-01  -1.96075112e-01   5.46451271e-01   5.25102139e-01\n",
      "    8.30025151e-02  -6.21350706e-01   1.93556488e-01  -5.65128386e-01\n",
      "    1.37549683e-01  -1.36414900e-01   1.86130947e-05  -3.74347150e-01\n",
      "   -2.40004823e-01   1.43346051e-02   3.92194808e-01   9.93039310e-02\n",
      "   -1.49026988e-02  -7.28551269e-01  -1.59558931e-05   3.42280380e-02\n",
      "   -1.66351214e-01   4.67529476e-01   2.02584177e-01   5.98942535e-03\n",
      "   -6.94020241e-02  -5.47055364e-01   4.54130247e-02  -3.04400951e-01\n",
      "    6.80328429e-01   9.97465551e-02   6.98300004e-01  -1.15843184e-01\n",
      "    8.60833505e-04   3.22512001e-01  -2.20513076e-01  -1.19440733e-02\n",
      "   -2.11127088e-04   6.93663299e-01   3.59367698e-01  -4.45726886e-02\n",
      "   -4.99409996e-02  -1.48852821e-02  -6.42490208e-01   6.68969333e-01\n",
      "    9.16883424e-02   1.06580228e-01   9.64802727e-02  -5.47348738e-01\n",
      "    5.61529815e-01  -1.31413087e-01  -5.98250404e-02   1.66102245e-01\n",
      "   -2.19678767e-02   5.86707192e-03   6.02290869e-01   6.99955747e-02\n",
      "    4.90152417e-03  -2.46790797e-01   5.07773936e-01  -4.07276809e-01\n",
      "    6.92723393e-01  -3.16001296e-01  -2.59156018e-01  -7.10830986e-01\n",
      "    1.72222853e-02  -2.88570467e-02  -6.03403449e-01  -3.79448414e-01\n",
      "    6.66414618e-01   5.16497232e-02   6.34195626e-01   1.11140069e-02\n",
      "   -6.34930611e-01   2.49497760e-02   2.78512090e-01   7.22650811e-03\n",
      "    1.57131463e-01  -7.38891065e-01  -7.01214671e-02   6.36278093e-03\n",
      "   -3.82163763e-01  -1.54540524e-01  -8.80956592e-04   3.89195443e-03\n",
      "    5.73063672e-01  -1.18120238e-02  -2.89712995e-01  -2.52188861e-01\n",
      "   -7.34686434e-01   2.54021911e-03   5.46948016e-01   1.96209271e-02\n",
      "   -1.34946988e-03   1.23018406e-01   1.20936371e-01   2.53362134e-02\n",
      "   -6.19025640e-02   6.02800965e-01  -6.23907777e-04  -5.98018527e-01\n",
      "   -1.74047276e-01  -3.52699906e-01   7.50860153e-03  -4.55592394e-01\n",
      "    1.66967601e-01   3.89151961e-01  -6.48311198e-01   1.32956773e-01\n",
      "    2.70990971e-02  -1.47954479e-01   4.26646322e-01   6.63946271e-01\n",
      "   -1.42260253e-01   4.15005654e-01  -3.88886988e-01  -2.42807288e-02\n",
      "   -6.41203940e-01  -1.64769366e-02   3.47666085e-01   8.75714570e-02\n",
      "   -6.50819063e-01  -5.90769172e-01   5.28099298e-01   1.25191566e-02\n",
      "   -7.36775935e-01  -1.92104317e-02  -1.24237698e-03   2.27769688e-01\n",
      "   -5.05227447e-01   6.11839071e-03   4.12634294e-03   1.52227640e-01\n",
      "    5.07742047e-01   4.14352685e-01   2.69707944e-02  -1.27975494e-02\n",
      "   -7.08889127e-01  -7.47558236e-01  -7.05045104e-01   1.93453521e-01\n",
      "   -2.81527545e-02   7.50181854e-01  -5.30569077e-01   3.17662776e-01\n",
      "    4.63445857e-02  -2.32629344e-01   9.52239707e-02   5.60191907e-02\n",
      "    1.37069821e-01  -2.26631477e-01   6.43734276e-01  -4.95256186e-01\n",
      "   -5.07911921e-01   9.42806620e-03  -1.25328009e-03  -3.21540296e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "f=h5py.File('E:\\\\AprilPaper\\\\LSTMVis\\\\05childbook\\\\states.h5','r')\n",
    "print type(f['output1'])\n",
    "print np.shape(f['output1'])\n",
    "print type(f['output1'][:1])\n",
    "print np.shape(f['output1'][:1])\n",
    "print f['output1'][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以构造的思路应该是：\n",
    "\n",
    "1. 提取出各个EHR的不同的states的sequence的数值，存入一个np.array\n",
    "2. 将多个EHR拼接成一个长的np.array\n",
    "3. 有几个states，就需要在h5文件中建立几个dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.h5\n",
    "里面有用的估计就是word那个dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'indices', <HDF5 dataset \"indices\": shape (1817, 20, 35), type \"<i8\">)\n",
      "(u'set_size', <HDF5 dataset \"set_size\": shape (), type \"<i8\">)\n",
      "(u'target', <HDF5 dataset \"target\": shape (1817, 20, 35), type \"<i8\">)\n",
      "(u'target_output', <HDF5 dataset \"target_output\": shape (1817, 20, 35), type \"<i8\">)\n",
      "(u'target_size', <HDF5 dataset \"target_size\": shape (1,), type \"<i8\">)\n",
      "(u'words', <HDF5 dataset \"words\": shape (1271912,), type \"<i8\">)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('E:\\\\AprilPaper\\\\LSTMVis\\\\05childbook\\\\train.h5','r') as f:\n",
    "    for i in f.iteritems():\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=h5py.File('E:\\\\AprilPaper\\\\LSTMVis\\\\05childbook\\\\train.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  5  1  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "print f['words'][:10]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以train.h5文件中是一个list就好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code\n",
    "```\n",
    "np.shape(admiSeqs_id)\n",
    "```\n",
    "(10742L, 60L, 1865L)\n",
    "共有10742个event，每个event是长度为60的one-hot向量\n",
    "\n",
    "在Code中，每一个for循环就已经便利了所有的数据\n",
    "只是每一次epoch循环都是以不同的顺序打乱的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
